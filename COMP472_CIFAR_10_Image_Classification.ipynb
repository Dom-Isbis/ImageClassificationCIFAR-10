{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOfaA6KnYUD6hszu5ioObQv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dom-Isbis/ImageClassificationCIFAR-10/blob/main/COMP472_CIFAR_10_Image_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "odKHeEjmzSKT"
      },
      "outputs": [],
      "source": [
        "# Managing imports\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Subset\n",
        "import torchvision\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.decomposition import PCA"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Overview\n",
        "\n",
        "* Initialize transformer to curate input dataset to ImageNet normalization standards.\n",
        "* Create 10 object classes with each 500 training and 100 test data, to conduct experiment on."
      ],
      "metadata": {
        "id": "4v-jM2LmNIh-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform input to 224 x 224 and apply ImageNet normalization\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Download CIFAR-10 dataset\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Select the first 500 training images and 100 test images per class\n",
        "def get_class_indices(dataset, num_per_class):\n",
        "    class_indices = {i: [] for i in range(10)}\n",
        "\n",
        "    for idx, (_, label) in enumerate(dataset):\n",
        "        if len(class_indices[label]) < num_per_class:\n",
        "            class_indices[label].append(idx)\n",
        "\n",
        "    selected_indices = [idx for indices in class_indices.values() for idx in indices]\n",
        "\n",
        "    return selected_indices\n",
        "\n",
        "train_indices = get_class_indices(train_dataset, 500)\n",
        "test_indices = get_class_indices(test_dataset, 100)\n",
        "\n",
        "# Stitches the sub dataset of 500:100 together across all 10 object classes in the CIFAR-10 dataset.\n",
        "train_subset = Subset(train_dataset, train_indices)\n",
        "test_subset = Subset(test_dataset, test_indices)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_subset, batch_size=64, shuffle=True, num_workers=2)\n",
        "test_loader = torch.utils.data.DataLoader(test_subset, batch_size=64, shuffle=False, num_workers=2)\n",
        "\n",
        "print(f'Training subset size: {len(train_subset)}')\n",
        "print(f'Test subset size: {len(test_subset)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EyT-CKImBWh9",
        "outputId": "e81d13bc-6694-4e9e-dabd-182a669b1f83"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Training subset size: 5000\n",
            "Test subset size: 1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained ResNet-18 model using the new weights parameter\n",
        "resnet18 = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
        "\n",
        "# Remove the final classification layer (fc layer)\n",
        "resnet18 = nn.Sequential(*list(resnet18.children())[:-1])\n",
        "\n",
        "# Model: CPU -> GPU, else GPU (for faster computation in parallel)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "resnet18.to(device)\n",
        "\n",
        "def extract_features(loader, model):\n",
        "    model.eval()\n",
        "    features = []\n",
        "    labels = []\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient calculation for speed\n",
        "        for inputs, targets in loader:\n",
        "            inputs = inputs.to(device)\n",
        "            outputs = model(inputs)  # Extract features\n",
        "            features.append(outputs.view(outputs.size(0), -1).cpu())  # Flatten and move to CPU\n",
        "            labels.append(targets)\n",
        "\n",
        "    features = torch.cat(features, dim=0)\n",
        "    labels = torch.cat(labels, dim=0)\n",
        "\n",
        "    return features, labels\n",
        "\n",
        "# Extract features for both train and test sets\n",
        "train_features, train_labels = extract_features(train_loader, resnet18)\n",
        "test_features, test_labels = extract_features(test_loader, resnet18)\n",
        "\n",
        "print(f'Training features shape: {train_features.shape}')\n",
        "print(f'Test features shape: {test_features.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cc5_v-VZ0VSF",
        "outputId": "948bcd02-eeac-4ded-8541-19d3ef2b870e"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training features shape: torch.Size([5000, 512])\n",
            "Test features shape: torch.Size([1000, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert tensors to numpy arrays\n",
        "train_features_np = train_features.numpy()\n",
        "test_features_np = test_features.numpy()\n",
        "\n",
        "# Apply PCA to reduce the features to 50 dimensions\n",
        "pca = PCA(n_components=50)\n",
        "train_features_pca = pca.fit_transform(train_features_np)\n",
        "test_features_pca = pca.transform(test_features_np)\n",
        "\n",
        "print(f'Training features after PCA: {train_features_pca.shape}')\n",
        "print(f'Test features after PCA: {test_features_pca.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BO5Hwa4GURkW",
        "outputId": "70179d9d-c56c-45fb-c9d2-4963e085f4fe"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training features after PCA: (5000, 50)\n",
            "Test features after PCA: (1000, 50)\n"
          ]
        }
      ]
    }
  ]
}